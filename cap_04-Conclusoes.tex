\chapter{Conclusões}

\label{CapConclusoes}

Desenvolveu-se uma aplicação que permite transferir certos movimentos faciais para um avatar computacional a partir de uma sequência de imagens capturadas por um par de câmeras. A técnica chave utilizada foi conectar características de um conjunto de pontos obtidos de um processo de rastreamento visual com os pesos de mistura da técnica de Mistura de Poses, permitindo gerar expressões variadas para o avatar a partir da combinação de um conjunto reduzido de expressões chave. 

Para o rastreamento visual, utilizou-se a biblioteca FaceAnalysis SDK para capturar 66 pontos chaves do rosto humano em uma sequência de imagens. Já para gerar os pesos de mistura, foi utilizada uma regra simples baseada na razão entre distâncias de pontos nomeados. Com o objetivo de tornar o processo robusto à distância do usuário ao par de câmeras, se utilizou a estimação de tridimensionalidade para tornar os pesos de mistura em uma função das distâncias reais entre os pontos e não de distâncias em pixeis das câmeras. Para isso, foi preciso uma etapa prévia de calibração das câmeras utilizadas. Além disso, os pesos de mistura passam por um filtro digital que suaviza os resultados. Dois tipos de filtros foram utilizados: um filtro de de média móvel de Hanning de comprimento três e um conjunto de filtros projetados pela técnica de corte de janela.  Apesar de muito menos elaborado, o primeiro filtro apresentou melhores resultados que os últimos. Entende-se que o ruído presente no sinal não possui comportamento espectral que justifique um projeto cuidadoso de um filtro passa-baixas. Um filtro curto, que ainda assim atenue frequências altas, performa melhor por impor um atraso menor no sinal de saída.

Uma série de experimentos foram realizados com o objetivo de medir a confiança em cada etapa do processo. A partir desses experimentos pôde-se inferir a distância que o usuário deve se posicionar do par de câmeras para que a técnica transfira os movimentos para o avatar de forma mais efetiva. Outro resultado foi que apesar de adequada para capturar o movimento da boca e das sobrancelhas, a regra associativa entre pontos e pesos de mistura não foi capaz de capturar outros movimentos faciais, como o movimento de bochechas e o piscar dos olhos. Em parte isso se deve a certa rigidez do algoritmo de rastreamento utilizado quanto ao formato do rosto, o que impede que este seja aplicado, pelo menos diretamente, para capturar nuâncias de certas expressões. Com isso, algumas das poses chave disponíveis não foram utilizadas na aplicação final.

Os resultados obtidos mostram a validade da técnica. Por exemplo, o programa desenvolvido foi capaz de sincronizar a abertura e o fechamento da boca do avatar enquanto o usuário conversava com a câmera em um dos vídeos de teste. Além disso, quando executando em máquinas comuns e ligado diretamente nas câmeras, o programa mostra os resultados em tempo de execução sem atraso perceptível entre entrada e saída. Por rodar em máquinas ordinárias e não exigir longas horas de processamento, a metodologia proposta se confirma como uma de baixo custo.



\section{Trabalhos Futuros}

A técnica de mistura de poses chaves se mostrou uma maneira simples de gerar expressões complexas a partir de medidas simples obtidas em uma imagem. No entanto, na implementação atual os pontos na malha das poses chaves estão limitados a serem os mesmos dos pontos da pose base a menos de uma translação. Com isso não pode-se animar uma pose chave onde, por exemplo, o avatar vira o pescoço. A geometria vetorial na mistura de poses não funcionaria adequadamente. É possível aplicar a técnica de mistura de poses com rotação dos pontos do modelo, desde que se conheça a transformação completa que deve ocorrer em cada ponto, não apenas sua translação. Uma possível direção para o trabalho seria implementar estas transformações e as misturas delas. Nota-se que isso implicaria, possivelmente, em mudar a representação dos modelos e acarretaria maior custo na renderização. 

Ainda sobre as poses chaves, durante o projeto o artista gráfico foi capaz de produzir mais poses bases do que criou-se regras associativas entre os pontos do rastreamento visual e os pesos de mistura. Por exemplo, o programa não possui regra capaz de reconhecer uma face com bochecha inchada. O problema principal é que o algoritmo de rastreamento visual não segue bem o contorno da bochecha nessa situação em particular, possivelmente devido à falta desta expressão nos dados onde foi treinado. Uma direção natural para a continuação do trabalho é o desenvolvimento de mais regras de associação entre imagem e pesos de mistura. O processo de treinamento descrito em \cite{facetracker} poderia ser repetido, sendo fornecido, dessa vez, um conjunto maior de dados de treinamento, incluindo as expressões que se deseja capturar. Uma abordagem mais simples seria construir rastreadores especializados que trabalhariam com dicas dos dados já capturados pela FaceAnalysis SDK. Apesar do algoritmo de rastreamento desta SDK não ser perfeito, ele fornece uma excelente pista de onde localizar as partes do rosto e essa informação poderia ser utilizada para construir rastreadores específicos para o que se quer medir. Por exemplo, é possível utilizar os pontos fornecidos para delimitar uma pequena janela de busca ao redor da bochecha onde se aplicaria algum truque para detectar bochechas cheias.

Tais melhorias poderiam tornar a execução do programa mais pesada e justificaria o desenvolvimento de um código que melhor aproveitasse ferramentas de aceleração gráfica. O código atual utiliza aceleração gráfica somente para renderizar o resultado final, de forma que todas as outras operações são realizadas por código  de máquina executado no processador principal  e em apenas uma linha de execução. Outra justificativa para o uso de aceleração gráfica em outras etapas da aplicação seria permitir que o programa rodasse suavemente com malhas mais pesadas. Na implementação atual deste trabalho obtém-se atraso significativo quando os modelos envolvidos apresentam dezenas de milhares de pontos.

Finalmente, em relação à captura de dados, a aplicação desenvolvida neste trabalho utiliza apenas um par de câmeras baratas. Apesar de resultados interessantes terem sido atingidos, certamente há limitações, ou no mínimo dificuldades, impostas pelo método de captura utilizado. 
Uma direção interessante em que se poderia evoluir seria a adição de um sensor de nuvem de pontos, como o Kinect, ao pipeline das técnicas. Apesar deste tipo de sensor ser mais caro que um par de câmeras, a adição de um sensor de nuvem de pontos não desclassificaria a aplicação como uma de baixo custo, ao se considerar o custo total do desenvolvimento de animação. Porém, como essa adição mudaria drasticamente o formato dos dados, seria necessário também desenvolver novas regras que associem pesos de mistura à nuvem de pontos.








